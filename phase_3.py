# -*- coding: utf-8 -*-
"""phase 3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CArcQr6U4Md9hn_YLj5mtbyoP-deP51m
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
!pip install gradio
import gradio as gr

df = pd.read_csv('/content/people-100 (2).csv')
df.head()

print("Missing values in each column:", df.isnull().sum())
df.dropna(inplace=True)
df.info()

print(df.describe())

df_reset = df.reset_index()
sns.countplot(x='index', data=df_reset)
plt.title('Distribution of Fraud and Non-Fraud Transactions')
plt.show()

plt.figure(figsize=(12, 8))
numeric_df = df.select_dtypes(include=np.number)
sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix')
plt.show()

print(df.columns)

df = df.drop(columns=['Index'])

print(df.head())

df = pd.read_csv('/content/people-100 (2).csv')
df = df.drop(columns=['Index'])

if 'Index' in df.columns:
    df = df.drop(columns=['Index'])
else:
    print("'Index' column not found in the dataframe.")

from sklearn.model_selection import train_test_split

X = df.drop(columns=['User Id'])

y = df['User Id']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = StandardScaler()

print(X.dtypes)

X = X.select_dtypes(include=[np.number])

print("Original columns:", X.columns)


if any(X.dtypes == 'object'):
    print("Encoding categorical columns...")
    X = pd.get_dummies(X, drop_first=True)
    print("New columns after encoding:", X.columns)
else:
    print("No categorical columns to encode.")

model = RandomForestClassifier(n_estimators=100, random_state=42)

print(X.dtypes)

print(type(X))

original_column_names = X.columns

print(X.shape)
print(len(original_column_names))

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

print(type(X_train))
print(X_train.shape)
print(X_train.dtypes)

import numpy as np
print(np.any(np.isnan(X_train)))
print(np.any(np.isinf(X_train)))

from sklearn.preprocessing import StandardScaler
import pandas as pd
import numpy as np


X_train = pd.DataFrame({
    'feature1': [1.0, 2.0, 3.0],
    'feature2': [4.0, 5.0, 6.0]
})

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)

print(X_train_scaled)

print(X_train.shape)
print(X_test.shape)

import numpy as np

print(np.any(np.isnan(X_test)))
print(np.any(np.isinf(X_test)))

from sklearn.preprocessing import StandardScaler
import pandas as pd


X_train = pd.DataFrame({
    'feature1': [1, 2, 3],
    'feature2': [4, 5, 6]
})
X_test = pd.DataFrame({
    'feature1': [2, 3],
    'feature2': [5, 6]
})

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(X_test_scaled)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
model = RandomForestClassifier(n_estimators=100, random_state=42)

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()

print(X_train_scaled.shape)
print(y_train.shape)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

df = pd.read_csv('/people-100 (2) (1).csv')


X = df.drop(columns=['Index'])
y = df['Index']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


X_train = X_train.reset_index(drop=True)
y_train = y_train.reset_index(drop=True)

!pip install scikit-learn
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer


categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()



numerical_pipeline = Pipeline([
    ('scaler', StandardScaler()),
])

categorical_pipeline = Pipeline([
    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),
])


preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_pipeline, numerical_features),
        ('cat', categorical_pipeline, categorical_features),
    ])
        l
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42)),
])

pipeline.fit(X_train, y_train)


y_pred = pipeline.predict(X_test)

!pip install scikit-learn
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score


df = pd.read_csv('/people-100 (2) (1).csv')

X = df.drop(columns=['User Id'])
y = df['User Id']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()
categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()

numerical_pipeline = Pipeline([
    ('scaler', StandardScaler()),
])

categorical_pipeline = Pipeline([
    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_pipeline, numerical_features),
        ('cat', categorical_pipeline, categorical_features),
    ])

pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42)),
])

pipeline.fit(X_train, y_train)

y_pred = pipeline.predict(X_test)


print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
print("Accuracy Score:", accuracy_score(y_test, y_pred))

!pip install gradio
import gradio as gr
import pandas as pd

def predict_fraud(v_inputs):
    # Define X within the function or pass it as an argument
    df = pd.read_csv('/people-100 (2) (1).csv')  # Assuming this is the correct path
    X = df.drop(columns=['User Id'])  # Assuming 'User Id' is the target column

    input_df = pd.DataFrame([v_inputs], columns=X.columns)

    # Assuming 'model' is defined and trained in a previous cell
    # If not, you need to load or train the model here as well.

    pred = model.predict(input_df)[0]

    # Check if predict_proba is available for your model
    try:
        prob = model.predict_proba(input_df)[0][1]
    except AttributeError:
        prob = 0.5  # Or some default value

    return {"Prediction": "Fraud" if pred == 1 else "Not Fraud", "Probability": round(prob, 3)}

input_components = [gr.Number(label=col) for col in pd.read_csv('/content/people-100 (2) (1).csv').drop(columns=['User Id']).columns]

gr.Interface(
    fn=predict_fraud,
    inputs=input_components,
    outputs=["text", "number"],
    title="üîê AI-Powered Credit Card Fraud Detection",
    description="Enter transaction features to detect fraud in real-time."
).launch()